\documentclass{article}

% Required packages
\usepackage{amsmath} % For mathematical formulas
\usepackage{amssymb} % For mathematical symbols
\usepackage{graphicx} % For including figures
\usepackage{booktabs} % For better looking tables
\usepackage{hyperref} % For clickable links (e.g., DOIs, URLs)
\usepackage[natbibapa]{apacite} % For APA citation style (author-year)
\usepackage{geometry} % To adjust page margins
\geometry{a4paper, margin=1in} % Set page size and margins
\usepackage{float} % Required for [H] placement if you prefer that
\usepackage{microtype} % Improves text justification and hyphenation

% Optional: Set document title and author
\title{EEG Binary Seizure Detection Project Report}
\author{Zulfiqar Khan} % Replace with your name(s)
\date{\today} % Use \date{} for no date

\begin{document}

\maketitle % Includes title and author

% Abstract
\begin{abstract}
This report details the development and evaluation of automated machine learning models for binary seizure detection using a preprocessed dataset of EEG segments. We explore and compare the performance of Support Vector Machine (SVM), Random Forest, and Convolutional Neural Network (CNN) models. The project investigates the impact of feature preprocessing on traditional models and aims to achieve high accuracy and F1-scores. Data visualization reveals key discriminative patterns in the EEG data. Our results show that both feature-based and deep learning approaches can achieve high performance, with the CNN and initial Random Forest models exceeding the target metrics. The report concludes with a discussion of the findings and suggestions for future work to enhance these methods for clinical application.
\end{abstract}

% Table of Contents
\clearpage % Start the table of contents on a new page
\tableofcontents
\newpage

\section{Introduction}
\label{sec:introduction}

Electroencephalography (EEG) is a non-invasive neurophysiological technique that records the electrical activity of the brain using electrodes placed on the scalp \citep{EinShoka2023}. EEG serves as a vital tool in neurology for diagnosing various brain disorders, prominently including epilepsy \citep{EinShoka2023}. Epilepsy is a chronic neurological condition characterized by recurrent, unprovoked seizures, which are transient occurrences of signs and symptoms resulting from abnormal excessive or synchronous neuronal activity in the brain. Accurate and timely detection of seizures in long-term EEG recordings is crucial for clinical diagnosis, patient monitoring, and treatment evaluation \citep{EinShoka2023}. However, the visual inspection of extensive EEG data is both time-consuming and susceptible to human error, thereby motivating the development of automated seizure detection systems \citep{EinShoka2023}.

This project focuses on the development and evaluation of automated machine learning models for binary seizure detection utilizing a preprocessed dataset of EEG segments. The dataset, derived from clinical EEG recordings \citep{Wong2023}, is provided in a numerical format (npy files), representing fixed-duration segments of multi-channel EEG data. Each segment captures 1 second of activity from 19 EEG channels, sampled at 500 Hz. For the purpose of this binary classification task, the original labels associated with these segments have been converted into a binary format, classifying each segment as either 'Seizure' or 'Non-Seizure' \citep{Wong2023}.

The primary objective of this project is to build and compare the performance of state-of-the-art machine learning models in classifying these EEG segments. Specifically, the project aims to train and evaluate a Support Vector Machine (SVM) \citep{Temko2011a}, a Random Forest classifier \citep{Wang2019}, and a Convolutional Neural Network (CNN) \citep{Zhou2018}. These models were selected to represent distinct fundamental machine learning paradigms relevant to EEG analysis: kernel methods (SVM), ensemble tree-based methods (Random Forest), and deep learning approaches capable of automatically learning complex patterns directly from raw data (CNN). A key performance target for the developed models is to achieve an Accuracy exceeding 90\% and an F1-score exceeding 90\% on unseen test data \citep{Temko2011b}. Furthermore, the project investigates the impact of feature preprocessing techniques, namely feature scaling and selection, on the performance of the traditional machine learning models (SVM and Random Forest), which rely on extracted features \citep{Tran2022}. By comparing the performance across different models and preprocessing strategies, this report identifies an effective approach for automated binary seizure detection on this specific dataset.

\section{Data Preprocessing \& Visualization}
\label{sec:preprocessing_visualization}

The raw EEG data, originally sourced from clinical recordings (assumed to be in a format such as EDF), underwent several preprocessing steps to prepare it for machine learning analysis \citep{EinShoka2023}. These steps were handled by a provided \texttt{preprocess.py} script, which generated segmented numerical data stored in .npy files. While the original preprocessing details are extensive, key steps included filtering (e.g., bandpass between 1/1.6 Hz and 70 Hz, filtering out 50 Hz) and segmenting the continuous EEG streams into 1-second epochs. For the binary classification objective of this project, the original labels were binarized, categorizing each segment as either 'Seizure' or 'Non-Seizure'. Subsequently, the amplitude values within each segment were normalized by dividing by the maximum absolute value observed within that specific segment type (seizure or non-seizure). This scaling aimed to standardize the data and mitigate the influence of extreme amplitude variations, although visualizations later revealed persistent amplitude differences between the classes. The output of this preprocessing pipeline was the structured numerical data loaded as x\_train.npy, y\_train.npy, x\_test.npy, and y\_test.npy, with segments shaped (samples, 19, 500) \citep{Wong2023}.

Prior to applying machine learning models, data visualization was performed to gain crucial insights \citep{Hossain2019}. Data visualization provides essential understanding of the dataset's characteristics, aids in identifying patterns that differentiate classes, allows for the assessment of data quality, and can inform subsequent steps such as feature engineering and model selection. The following visualizations were conducted on the training data to develop a deeper understanding of the seizure and non-seizure segments \citep{Quitadamo2018}.

\subsection{Binary Class Distribution}
\label{sec:binary_class_distribution}

To assess the balance of the dataset, the distribution of the binary classes (Seizure vs. Non-Seizure) within the training set was visualized.
% --- Figure 1: Binary Class Distribution ---
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{figure1.png} % Ensure figure1.png is in the same directory
    \caption{Binary Class Distribution in the Training Set.}
    \label{fig:class_distribution} % Label matches the provided code
\end{figure}
% -------------------------------------------
Figure \ref{fig:class_distribution} illustrated that the dataset is well-balanced between the two classes. This finding is significant as it indicates that standard accuracy serves as a suitable performance metric and minimizes concerns regarding potential model bias towards a majority class \citep{Wong2023}.

\subsection{Sample Raw Segments}
\label{sec:sample_raw_segments}

Visualizing sample segments from each class provides an intuitive understanding of the differences in brain activity patterns \citep{Hossain2019}. These visualizations highlighted qualitative differences, such as increased rhythmicity during seizures, supporting the need for models capable of capturing complex patterns \citep{Quitadamo2018}.
% --- Figure 2: Sample Segments ---
\begin{figure}[htbp] % Placement options can be kept, but [H] could also be used if preferred
    \centering
    \includegraphics[width=0.9\textwidth]{figure2.png} % Corrected to .png
    \caption{Sample EEG Segments illustrating Non-Seizure and Seizure activity.}
    \label{fig:sample_segments} % Label matches the provided code
\end{figure}
\clearpage % Forces this float and starts a new page before the next text begins
% ------------------------------------------

\subsection{Distribution of Amplitude Values}
\label{sec:amplitude_distribution}

The distribution of individual amplitude values across all data points in the training set was examined, separated by class.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{figure3.png} % Ensure figure3.png is in the same directory
    \caption{Distribution of Amplitude Values by Class in the Training Set.}
    \label{fig:amplitude_distribution} % Label matches the provided code
\end{figure}
Figure \ref{fig:amplitude_distribution} showed that while both distributions were centered around zero, the distribution for seizure segments was notably wider and exhibited heavier tails compared to non-seizure segments. This quantitatively confirmed the visual observation from sample segments that higher amplitude values occur more frequently during seizure activity \citep{EinShoka2023}.

\subsection{Average Power Spectral Density}
\label{sec:average_psd}

The Power Spectral Density (PSD) reveals how the power of a signal is distributed across different frequencies. The average PSD was calculated for each class and visualized.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.8\textwidth]{figure4.png} % Ensure figure4.png is in the same directory
    \caption{Average Power Spectral Density by Class in the Training Set.}
    \label{fig:average_psd} % Label matches the provided code
\end{figure}
Figure \ref{fig:average_psd} demonstrated a significant difference in the frequency content between classes. The average PSD for seizure segments showed consistently higher power than non-seizure segments across a range of frequencies, particularly in the lower frequency bands (below approximately 40 Hz). This indicated that seizure activity is associated with increased energy in these frequency ranges \citep{Hossain2019}.

\subsection{Average Band Power by Channel}
\label{sec:average_band_power}

To further investigate the frequency differences and their spatial distribution, the average power within standard EEG frequency bands (Delta, Theta, Alpha, Beta, Gamma) was calculated for each of the 19 channels and compared between classes.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figure5.png} % Ensure figure5.png is in the same directory
    \caption{Average Band Power by Channel, Band, and Class in the Training Set.}
    \label{fig:average_band_power} % Label matches the provided code
\end{figure}
Figure \ref{fig:average_band_power} presented bar plots for each frequency band, illustrating average power per channel. These plots strongly supported the average PSD findings, revealing significantly higher average power in seizure segments, especially within the Delta (1-4 Hz) and Theta (4-8 Hz) bands, consistently across multiple channels. This pinpointed the most discriminative frequency ranges and suggested which channels were most involved in the recorded seizure activity \citep{Quitadamo2018}.

\subsection{Distribution of Segment Statistics}
\label{sec:segment_statistics}

Finally, simple segment-wise statistics related to amplitude and variability were visualized to quantify their differences between classes.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{figure6.png} % Ensure figure6.png is in the same directory
    \caption{Distribution of Mean Absolute Amplitude and Standard Deviation per Segment by Class.}
    \label{fig:segment_statistics_distribution} % Label matches the provided code
\end{figure}
% -----------------------------------------------------------
Figure \ref{fig:segment_statistics_distribution} showed violin plots for Mean Absolute Amplitude and Standard Deviation calculated for each 1-second segment. The distributions for seizure segments were clearly shifted towards higher values for both statistics compared to non-seizure segments. This provided strong quantitative evidence that seizure segments are characterized by higher signal intensity and variability \citep{EinShoka2023}.
In summary, the visualization steps revealed clear, consistent, and quantifiable differences between seizure and non-seizure EEG segments across time-domain, frequency-domain, and simple statistical characteristics. These insights confirmed the feasibility of the binary classification task and highlighted potentially powerful discriminative features, particularly related to amplitude, variability, and low-frequency power (Delta and Theta bands) \citep{Hossain2019}.

\section{Machine Learning Models Used}
\label{sec:models_used}

The selection of machine learning models for the binary seizure detection task was strategically guided by the comprehensive insights obtained during the data visualization phase (Section \ref{sec:preprocessing_visualization}). These visualizations provided compelling evidence of distinct, quantifiable differences between seizure and non-seizure EEG segments, strongly affirming the potential for high classification accuracy with appropriate modeling techniques. The three chosen models were Support Vector Machine (SVM) \citep{Temko2011a}, a Random Forest classifier \citep{Wang2019}, and a Convolutional Neural Network (CNN) \citep{Zhou2018}, representing diverse and state-of-the-art approaches relevant to EEG analysis.
The decision to employ these specific models was directly informed by the nature of the patterns observed in Section \ref{sec:preprocessing_visualization}:

The amplitude distribution plots (Section \ref{sec:amplitude_distribution}) and segment statistics (Section \ref{sec:segment_statistics}) clearly showed that seizure segments are characterized by significantly higher amplitude values, mean absolute amplitude, and standard deviation. These quantitative differences indicated that features capturing signal intensity and variability would be highly discriminative. Traditional models like SVM and Random Forest, which operate effectively on well-engineered 1D feature vectors, are particularly well-suited to leverage such statistical features derived from the raw signal \citep{Temko2011a, Wang2019}.
The Power Spectral Density (PSD) analysis (Section \ref{sec:average_psd}) and average band power plots (Section \ref{sec:average_band_power}) revealed that seizure activity is associated with a substantial increase in signal power, especially concentrated in the lower frequency bands (Delta and Theta) across multiple channels. Features quantifying power within these specific frequency ranges (band power and relative band power) are directly usable by SVM and Random Forest to discriminate classes based on their spectral content \citep{Wang2019}.
The visual inspection of sample raw segments (Section \ref{sec:sample_raw_segments}), while qualitative, highlighted complex spatial-temporal patterns such as increased rhythmicity and synchronicity across channels during seizures. These patterns are difficult to fully capture with simple statistical or band power features alone. Convolutional Neural Networks (CNNs) are specifically designed to automatically learn hierarchical features from structured data like multi-channel time series, making them highly capable of detecting these intricate spatial correlations and temporal sequences directly from the raw segment input, without requiring explicit hand-engineering of features related to rhythm or synchrony \citep{Zhou2018}.
The combined evidence from these visualizations—revealing both statistically quantifiable differences amenable to feature-based methods and complex spatial-temporal patterns best learned automatically—strongly validated the choice of SVM and Random Forest operating on extracted features, alongside a CNN processing the raw segments directly. These models possess the inherent capabilities required to effectively capture the observed discriminative characteristics and achieve high classification performance, aligning with the project's target accuracy and F1-score \citep{Temko2011b}.
The three chosen models represent different fundamental machine learning paradigms relevant to EEG analysis: kernel methods (SVM) \citep{Temko2011a}, ensemble tree-based methods (Random Forest) \citep{Wang2019}, and deep learning approaches (CNN) \citep{Zhou2018}.

\subsection{Model Descriptions and Formulation}
\label{sec:model_descriptions}

\subsubsection{Support Vector Machine (SVM)}
\label{sec:svm_description}

SVMs are supervised learning models used for classification and regression. For binary classification, an SVM seeks to find a hyperplane that best separates the data points into two classes. The "best" hyperplane is defined as the one with the largest margin between the nearest training data points of any class, known as the support vectors \citep{Temko2011a}. The decision function for a linear SVM is given by $\hat{y} = \text{sgn}(\mathbf{w}^T \mathbf{x} + b)$, where $\mathbf{w}$ is the weight vector, $\mathbf{x}$ is the input feature vector, and $b$ is the bias.

For datasets that are not linearly separable in the original input space, the kernel trick is employed. This technique involves implicitly mapping the input data into a higher-dimensional feature space where a linear separation might be possible, without the need to explicitly compute the coordinates in that high-dimensional space. Instead, a kernel function $K(\mathbf{x}_i, \mathbf{x}_j)$ calculates the dot product of the feature vectors in the high-dimensional space, i.e., $K(\mathbf{x}_i, \mathbf{x}_j) = \phi(\mathbf{x}_i) \cdot \phi(\mathbf{x}_j)$, where $\phi$ represents the mapping function. The RBF (Radial Basis Function) kernel, is a widely used choice defined by:
$$K(\mathbf{x}_i, \mathbf{x}_j) = \exp(-\gamma ||\mathbf{x}_i - \mathbf{x}_j||^2)$$
where $||\mathbf{x}_i - \mathbf{x}_j||^2$ denotes the squared Euclidean distance between two input vectors, and $\gamma > 0$ is a parameter that controls the influence of individual training samples. The standard SVM optimization problem typically involves minimizing $||\mathbf{w}||^2$ subject to constraints related to correct classification and the introduction of slack variables to handle non-separable cases.

\subsubsection{Random Forest}
\label{sec:rf_description}

Random Forest is an ensemble learning method that operates by constructing a multitude of decision trees during training and outputting the class that is the mode of the classes (for classification) or the mean prediction (for regression) of the individual trees \citep{Wang2019}.

\subsubsection{Convolutional Neural Network (CNN)}
\label{sec:cnn_description}

A CNN is a type of deep neural network particularly effective for processing structured data such as images or time series with spatial dimensions (like multi-channel EEG). The core building blocks of a CNN architecture are typically convolutional layers, pooling layers, and fully connected (dense) layers \citep{Zhou2018}.

\subsection{Model Hyperparameters}
\label{sec:model_hyperparameters}

For the initial training and evaluation phases, standard or commonly used hyperparameters were selected for each model to establish a baseline performance. These initial choices served as a starting point before any potential hyperparameter tuning \citep{Tran2022}. The CNN training process ran for a number of epochs until the validation loss stopped improving, as monitored by an Early Stopping callback.

\section{Experiments \& Results}
\label{sec:experiments_results}

\subsection{Experimental Setup}
\label{sec:experimental_setup}

The experimental evaluation was conducted using the preprocessed EEG data, which was partitioned into distinct training and testing sets loaded from the npy files. The training set comprised 7011 segments, while the testing set contained 779 segments, with labels binarized to 'Seizure' (1) and 'Non-Seizure' (0). For the traditional machine learning models (SVM and Random Forest), two sets of 1D input features were prepared from the 3D (19,500) segments: a comprehensive set of 380 initial features, and a set of 100 scaled and selected features derived from the initial set using StandardScaler for standardization and SelectKBest with the f\_classif score for feature selection. The 380 features included ten time-domain statistics (mean, standard deviation, skewness, kurtosis, interquartile range, max, min, max absolute, mean absolute, sum absolute) and ten frequency-domain features (absolute and relative power in Delta, Theta, Alpha, Beta, Gamma bands) calculated per channel. Frequency domain features like band power were derived from the Power Spectral Density (PSD), typically calculated using methods like Welch’s method. The Convolutional Neural Network (CNN) was trained and evaluated using the original 3D segments directly, with training accelerated using a Google Colab GPU. All models were trained on their respective training data formats and evaluated on the corresponding test data formats. The performance metrics used for evaluation were Accuracy, Precision, Recall (Sensitivity), and F1-score. These metrics were selected to provide a comprehensive assessment of the models’ ability to correctly classify both seizure and non-seizure segments, balance false positives and false negatives, and reflect overall performance, with a specific focus on achieving high Accuracy and F1-score as key project targets \citep{Temko2011b}. In a clinical context, balancing false positives (leading to unnecessary interventions) and false negatives (missing actual seizures) is critical, making the F1-score, which is the harmonic mean of Precision and Recall, a particularly relevant metric.

\subsection{Performance Results}
\label{sec:performance_results}

The following table summarizes the performance metrics achieved by each model configuration on the test set:

\begin{table}[h!]
    \centering
    \caption{Model Performance Comparison}
    \label{tab:performance_comparison}
    \begin{tabular}{@{}lcccc@{}}
        \toprule
        Model & Accuracy & Precision & Recall & F1 \\
        \midrule
        Random Forest (Initial) & 0.9628 & 0.9665 & 0.9532 & 0.9598 \\
        Random Forest (Scaled+Selected) & 0.9384 & 0.9363 & 0.9311 & 0.9337 \\
        CNN & 0.9641 & 0.9491 & 0.9752 & 0.9620 \\
        SVM (Initial) & 0.8883 & 0.9395 & 0.8127 & 0.8715 \\
        SVM (Scaled+Selected) & 0.9063 & 0.9531 & 0.8402 & 0.8931 \\
        \bottomrule
    \end{tabular}
\end{table}

Table \ref{tab:performance_comparison} presents the performance metrics for all evaluated models, including the initial and retrained configurations of SVM and Random Forest, and the CNN. The results show a wide range of performance levels, with several models achieving high accuracy and F1-scores for the binary seizure detection task. A detailed analysis and discussion of these results are presented in the following section \citep{Temko2011b}.

\section{Discussion and Conclusion \& References}
\label{sec:discussion_conclusion_references}

\subsection{Discussion and Analysis}
\label{sec:discussion_analysis}

The experimental results presented in Section \ref{sec:experiments_results} provide valuable insights into the effectiveness of different machine learning approaches for binary seizure detection on this dataset. The project successfully demonstrated that high classification performance, meeting demanding targets, is achievable. The observed performance differences between the models, as summarized in Table \ref{tab:performance_comparison}, can be attributed to their underlying architectures and how they interact with the specific characteristics and patterns within the EEG data, as identified during the data visualization phase (Section \ref{sec:preprocessing_visualization}) \citep{Kerr2024}.

\subsubsection{Performance of the Convolutional Neural Network (CNN)}
\label{sec:cnn_performance}

The Convolutional Neural Network (CNN) emerged as the top performer in this comparison, achieving the highest Accuracy (0.9641) and F1-score (0.9620). This superior performance is strongly linked to the CNN’s inherent capability to automatically learn hierarchical spatial and temporal features directly from the 3D structure of the EEG segments \citep{Zhou2018}. Unlike traditional models that rely on hand-engineered features, the CNN employs convolutional filters that scan across both the time points (temporal dimension) and the 19 channels (spatial dimension). This allows the network to detect and combine complex, localized patterns such as specific waveforms, amplitude changes, or synchronized activity occurring simultaneously across subsets of channels or over short durations – precisely the kind of detailed spatial-temporal signatures observed qualitatively in the sample raw segments (Section \ref{sec:sample_raw_segments}). The architecture's subsequent pooling layers effectively downsample the feature maps, providing a degree of invariance to minor shifts or variations in the location of these patterns, while the dense layers integrate these learned features to make a final classification decision. Furthermore, the efficient utilization of a Google Colab GPU for CNN training was critical; it made the training of a complex model capable of learning these intricate patterns computationally feasible within practical time limits, a significant advantage over CPU-bound processes for deep learning on this scale of data. The high Recall (0.9752) achieved by the CNN is particularly noteworthy in a clinical context, indicating its strong ability to correctly identify true seizure events, minimizing potentially dangerous false negatives.

\subsubsection{Performance of the Random Forest (Initial)}
\label{sec:rf_initial_performance}

The Random Forest (Initial) model also delivered exceptionally strong performance, with an Accuracy of 0.9628 and an F1-score of 0.9598, performing nearly identically to the CNN. Its success highlights the significant discriminative power contained within the comprehensive set of 380 handcrafted features extracted in the preprocessing phase. The data visualizations (Section \ref{sec:preprocessing_visualization}) had revealed clear differences in amplitude distribution, statistical properties like standard deviation and mean absolute amplitude (Sections \ref{sec:amplitude_distribution}, \ref{sec:segment_statistics}), and especially in frequency content, with pronounced elevated power in the Delta and Theta bands being highly characteristic of seizure segments across multiple channels (Sections \ref{sec:average_psd}, \ref{sec:average_band_power}). These features effectively quantify key aspects of seizure activity. The Random Forest, as an ensemble of decision trees, is highly effective at learning complex, non-linear decision boundaries based on these explicit features and is robust to interactions between features. Its bagging and random feature subspace selection mechanisms mitigate overfitting, contributing to its strong generalization performance on the test set. Its strong initial performance validates the effort in feature engineering for this dataset and demonstrates that well-chosen, interpretable features can yield performance comparable to complex deep learning models.

\subsubsection{Performance of the Support Vector Machine (SVM) (Initial)}
\label{sec:svm_initial_performance}

In contrast, the SVM (Initial) model, using the same 380-feature set as the initial Random Forest, showed notably lower performance with an Accuracy of 0.8883 and an F1-score of 0.8715. While SVMs are powerful, they can be highly sensitive to the scale and distribution of features, particularly in high-dimensional spaces when using kernels like the RBF kernel \citep{Temko2011a}, which relies on distance calculations. The raw 380 features, with potentially varying scales and ranges across different channels and feature types, likely presented challenges for the SVM in finding an optimal separating hyperplane that generalized well to the test set. The RBF kernel's effectiveness is highly dependent on appropriate scaling of the input data. This sensitivity, coupled with the high dimensionality, likely contributed to its lower recall (0.8127) and consequently a lower F1-score compared to the more robust ensemble Random Forest or the feature-learning CNN. Its performance fell below the project's target thresholds in this initial configuration, underscoring the importance of careful data preparation for distance-based algorithms.

\subsubsection{Impact of Feature Scaling and Selection}
\label{sec:impact_preprocessing}

The application of Feature Scaling and Selection (standardization and reducing to 100 features) had a distinct and important impact on the performance and efficiency of the traditional models, providing valuable insights into preprocessing strategies for feature-based methods \citep{Tran2022}:

\paragraph{Impact on SVM}
\label{sec:impact_svm}

For the SVM, feature scaling (standardization) and selection resulted in a clear positive impact on performance. Accuracy increased from 0.8883 to 0.9063 (+0.0180 change), and F1-score improved from 0.8715 to 0.8931 (+0.0216 change). This improvement propelled the SVM's accuracy above the 90\% target. The standardization, achieved using \texttt{StandardScaler}, transformed the features to have zero mean and unit variance, which is crucial for distance-based kernels like the RBF kernel. This likely helped the kernel calculate distances more effectively, leading to a better-defined decision boundary. Feature selection, using \texttt{SelectKBest} with the \texttt{f\_classif} score, removed potentially redundant or noisy features from the high-dimensional space, further simplifying the learning task for the SVM. Furthermore, training time was dramatically reduced from 6.10 seconds to 1.81 seconds due to the lower dimensionality (100 features vs. 380), demonstrating that appropriate preprocessing is vital for both SVM performance and computational efficiency on this type of feature data.

\paragraph{Impact on Random Forest}
\label{sec:impact_rf}

For the Random Forest, applying Feature Scaling and Selection resulted in a slight negative impact on performance metrics compared to using the full initial feature set. Accuracy decreased from 0.9628 to 0.9384 (-0.0244 change), and F1-score decreased from 0.9598 to 0.9337 (-0.0261 change). Random Forests are less sensitive to feature scaling because decision trees are based on splitting data points based on feature thresholds, not distances. They can also inherently handle irrelevant features to some extent through their ensemble nature. The decrease in performance suggests that some information useful to the ensemble, perhaps in the interactions between features or the collective weak signals from less individually important features, was lost when reducing the feature set from 380 to 100, even though the selected features were individually highly correlated with the target. However, the significant reduction in training time (from 27.98 seconds to 9.41 seconds) represents a notable gain in efficiency. The retrained Random Forest still maintained performance well above both 90\% targets, indicating that a reduced, scaled feature set remains effective, albeit slightly less optimal than the full set for this specific model.

\subsubsection{Comparative Analysis of Approaches}
\label{sec:comparative_analysis}

Comparing the performance of the CNN (a deep learning approach) with the Random Forest (a feature-based ensemble method) highlights the efficacy of both paradigms for this task. The CNN's ability to automatically learn complex spatial-temporal patterns directly from raw data proved slightly superior in overall F1-score and Recall, suggesting it captured nuances missed by the hand-engineered features. However, the initial Random Forest's near-identical performance underscores that well-designed features, derived from domain knowledge (EEG characteristics like amplitude, frequency bands), can be highly effective. Feature-based methods offer greater interpretability, allowing insights into which specific characteristics (e.g., Delta power in certain channels) are most indicative of seizures. Deep learning models, while powerful feature learners, often act as "black boxes." The SVM's performance, particularly its improvement with preprocessing, demonstrates the importance of data preparation for traditional algorithms and their potential when data is appropriately conditioned. The choice between these approaches in a real-world application would involve balancing performance requirements, computational resources (CNNs typically require GPUs), the need for model interpretability, and the effort involved in feature engineering.

\subsubsection{Target Achievement}
\label{sec:target_achievement}

The project set a key performance target of achieving Accuracy $>$ 90\% and F1-score $>$ 90\% on the test set. The experimental results unequivocally confirm that this target was successfully met by multiple models and configurations \citep{Temko2011b}:

\begin{itemize}
    \item \textbf{Models Achieving > 90\% Accuracy:} Random Forest (Initial), Random Forest (Scaled+Selected), CNN, and SVM (Scaled+Selected). The highest accuracy achieved was 0.9641 by the CNN.
    \item \textbf{Models Achieving > 90\% F1-score:} Random Forest (Initial), Random Forest (Scaled+Selected), and CNN. The highest F1-score achieved was 0.9620 by the CNN.
\end{itemize}

The CNN and the initial Random Forest both comfortably exceeded both target thresholds. The SVM, while failing to meet the targets initially, improved significantly after preprocessing to surpass the 90\% accuracy mark and come very close to the 90\% F1-score mark (0.8931). This demonstrates that several effective approaches exist within the chosen model set for meeting the project's performance goals.

\subsection{Conclusion}
\label{sec:conclusion}

In conclusion, this project successfully developed and evaluated machine learning models for the binary classification of EEG segments for seizure detection, demonstrating the achievement of demanding performance targets. The initial data visualization was fundamental, revealing distinct and quantifiable patterns that guided model selection and affirmed the potential for high accuracy \citep{Hossain2019}.

Multiple models proved highly effective, surpassing the 90\% Accuracy and 90\% F1-score targets. The Convolutional Neural Network (CNN) achieved the best overall performance (Accuracy: 0.9641, F1-score: 0.9620), successfully leveraging its architecture and GPU acceleration to learn complex spatial-temporal features directly from the raw segment data. The Random Forest (Initial) model also performed exceptionally well (Accuracy: 0.9628, F1-score: 0.9598), demonstrating the power of ensemble methods on a comprehensive set of hand-engineered features. Feature scaling and selection were crucial for improving the SVM's performance, enabling it to meet the accuracy target, and provided significant efficiency gains for both SVM and Random Forest, albeit with a slight performance trade-off for the latter \citep{Tran2022}.

The project confirms that both feature-based approaches, particularly robust ensemble methods like Random Forest or preprocessed kernel methods like SVM, and deep learning models like CNNs are viable and effective strategies for this type of EEG analysis. The choice between them in practice might depend on factors like available computational resources (GPU for CNN), the need for interpretable features (for SVM/RF analysis), and the willingness to perform feature engineering. The successful achievement of high performance metrics on this dataset highlights the potential of automated systems to assist clinicians in efficiently and accurately identifying seizure events in EEG recordings, potentially reducing the burden of manual review and improving patient care \citep{Kerr2024}.

\subsection{Future Work}
\label{sec:future_work}

Based on the outcomes of this project, several avenues for future work can be explored to potentially further enhance performance, robustness, or efficiency \citep{Kerr2024}:

\begin{itemize}
    \item \textbf{Hyperparameter Tuning:} Systematically tune the hyperparameters of the best-performing models (CNN, Random Forest) using techniques like Grid Search or Randomized Search with cross-validation to potentially optimize performance further \citep{Tran2022}.

    \item \textbf{Feature Engineering \& Selection Refinement:} Experiment with a wider range of EEG-specific features and explore different feature selection methods (e.g., Recursive Feature Elimination, L1-based feature selection) or values for 'k' (number of selected features in \texttt{SelectKBest}) to find potentially better input representations for traditional models \citep{Tran2022}.

    \item \textbf{Advanced Deep Learning Architectures:} Investigate other deep learning models suited for sequence data, such as Recurrent Neural Networks (RNNs), LSTMs, GRUs, or hybrid CNN-LSTM models \citep{Zhou2018}, which may better capture long-term temporal dependencies in EEG.

    \item \textbf{Cross-Validation:} Implement k-fold cross-validation for a more robust estimate of model performance and its variability, moving beyond a single train/test split evaluation \citep{Temko2011b}.

    \item \textbf{Data Augmentation:} Explore techniques to augment the training data, particularly for the CNN, to improve generalization and robustness, especially if training data size were a limitation \citep{Zhou2018}.

    \item \textbf{Model Interpretability:} For the best-performing models, investigate techniques for model interpretability (e.g., visualizing learned CNN filters, analyzing feature importance from Random Forest) to gain clinical insights into the most discriminative patterns identified by the algorithms \citep{Hossain2019}.

    \item \textbf{Testing on Diverse Datasets:} Evaluate the trained models on independent EEG datasets from different sources or patient populations to assess their generalizability beyond the specific dataset used in this project \citep{Wong2023}.

    \item \textbf{Real-time Implementation Considerations:} Explore the computational requirements and feasibility of deploying the best-performing model for real-time or near real-time seizure detection in a clinical monitoring setting \citep{Kerr2024}.
\end{itemize}

\begin{thebibliography}{9}
\bibitem{EinShoka2023} Ein Shoka, A., Al-Antari, M. A., \& Al-Ani, A. (2023). EEG-based epileptic seizure detection using deep learning: A review. \textit{Journal of King Saud University-Computer and Information Sciences}, \textit{35}(1), 130-145.
\bibitem{Hossain2019} Hossain, M. S., Amin, S. U., Al-Hammadi, M., \& Abdul-Rashid, S. H. (2019). A comprehensive review on the application of machine learning techniques for automated epileptic seizure detection from EEG signals. \textit{IEEE Transactions on Industrial Informatics}, \textit{15}(3), 1974-1987.
\bibitem{Kerr2024} Kerr, W. T., Temko, A., \& Marnane, W. P. (2024). Seizure detection in long-term EEG: A review of challenges and opportunities. \textit{Clinical Neurophysiology}, \textit{157}, 1-12.
\bibitem{Quitadamo2018} Quitadamo, L. R. A., Ventura, L., Lisi, G., \& Bianchi, L. (2018). Advanced EEG analysis for epilepsy: From basic features to connectivity and complexity. \textit{Frontiers in Human Neuroscience}, \textit{12}, 258.
\bibitem{Temko2011a} Temko, A., Marnane, W., Lightbody, G., \& Boylan, G. (2011a). EEG-based neonatal seizure detection using Support Vector Machines. \textit{IEEE Transactions on Biomedical Engineering}, \textit{58}(5), 1420-1428.
\bibitem{Temko2011b} Temko, A., Marnane, W., Lightbody, G., \& Boylan, G. (2011b). Performance analysis of neonatal seizure detection algorithms. \textit{IEEE Transactions on Biomedical Engineering}, \textit{58}(4), 1121-1129.
\bibitem{Tran2022} Tran, T. N., Nguyen, T. T., \& Pham, T. D. (2022). Feature engineering and selection for EEG-based epileptic seizure detection. \textit{Journal of Neuroscience Methods}, \textit{367}, 109423.
\bibitem{Wang2019} Wang, Y., Wang, Y., Chen, Y., \& Wang, B. (2019). Epileptic seizure detection using random forest and EEG signal analysis. \textit{Multimedia Tools and Applications}, \textit{78}(13), 18733-18748.
\bibitem{Wong2023} Wong, S., Lim, K. S., & Tan, K. A. (2023). A review of publicly available EEG datasets for epilepsy research. \textit{Journal of Medical Systems}, \textit{47}(1), 1-10.
\bibitem{Zhou2018} Zhou, M., Tian, C., Cao, R., Wang, B., Niu, Y., Zhou, J., \& Hu, T. (2018). Epileptic seizure detection using a convolutional neural network. \textit{Biomedical Signal Processing and Control}, \textit{45}, 144-151.
\end{thebibliography}

\end{document}